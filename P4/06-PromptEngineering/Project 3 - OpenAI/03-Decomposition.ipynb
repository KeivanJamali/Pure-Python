{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompositioning_system_prompt = \"\"\"\n",
    "You are a helpful assistant trained to generates multiple sub-questions related to the a prompt.\\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answered perfectly with LLMs.\\n\\n\n",
    "Answer in this format:\n",
    "1- sub-question-one\n",
    "2- sub-question-two\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "decompositioning_human_prompt = \"\"\"\n",
    "Prompt that is needed to convert to sub-questions:\\n\n",
    "<prompt>\\n\n",
    "{question}\\n\n",
    "</prompt>\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\nYou are a helpful assistant trained to generates multiple sub-questions related to the a prompt.\\n\\nThe goal is to break down the input into a set of sub-problems / sub-questions that can be answered perfectly with LLMs.\\n\\n\\nAnswer in this format:\\n1- sub-question-one\\n2- sub-question-two\\n...\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='\\nPrompt that is needed to convert to sub-questions:\\n\\n<prompt>\\n\\n{question}\\n\\n</prompt>\\n\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(decompositioning_system_prompt)\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(decompositioning_human_prompt, input_variables=[\"question\"])\n",
    "prompt_decomposition = ChatPromptTemplate([system_prompt, human_prompt])\n",
    "prompt_decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "models = {\"Google\": [\"gemma2-9b-it\", \"gemma-7b-it\"],\n",
    "          \"Groq\": [\"llama3-groq-70b-8192-tool-use-preview\", \"llama3-groq-8b-8192-tool-use-preview\"],\n",
    "          \"Meta\": [\"llama-3.1-70b-versatile\", \"llama-3.1-8b-instant\", \"llama-3.2-1b-preview\", \"llama-3.2-3b-preview\", \"llama-3.2-11b-vision-preview\", \"llama-3.2-90b-vision-preview\", \"llama-guard-3-8b\", \"llama3-70b-8192\", \"llama3-8b-8192\"],\n",
    "          \"Mistral\": [\"mixtral-8x7b-32768\"],\n",
    "          \"OpenAI\": [\"whisper-large-v3\", \"whisper-large-v3-turbo\"]}\n",
    "model_groq = ChatGroq(model=models[\"Meta\"][0], temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from IPython.display import Markdown\n",
    "def generate_sub_queries(query):\n",
    "    chain = (prompt_decomposition \n",
    "             | model_groq \n",
    "             | StrOutputParser()\n",
    "             | (lambda x: x.split(\"\\n\")))\n",
    "    questions_produced = chain.invoke({\"question\":query})\n",
    "    display(Markdown(\"==========================================\\n\\n\" + \"Sub-Questions  :  \\n\\n\" + \"\\n\\n\".join(questions_produced) + \"\\n\\n==========================================\"))\n",
    "    return \"\\n\\n\".join(questions_produced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "==========================================\n",
       "\n",
       "Sub-Questions  :  \n",
       "\n",
       "1- What is Keivan Jamali's nationality?\n",
       "\n",
       "2- What is Keivan Jamali's profession or occupation?\n",
       "\n",
       "3- Is Keivan Jamali a public figure, and if so, in what context?\n",
       "\n",
       "4- What are Keivan Jamali's notable achievements or contributions?\n",
       "\n",
       "5- Is there any available information on Keivan Jamali's personal life or background?\n",
       "\n",
       "6- Is Keivan Jamali associated with any specific industry or field?\n",
       "\n",
       "7- Are there any notable works or projects attributed to Keivan Jamali?\n",
       "\n",
       "8- Is Keivan Jamali active on social media or other online platforms?\n",
       "\n",
       "=========================================="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"1- What is Keivan Jamali's nationality?\\n\\n2- What is Keivan Jamali's profession or occupation?\\n\\n3- Is Keivan Jamali a public figure, and if so, in what context?\\n\\n4- What are Keivan Jamali's notable achievements or contributions?\\n\\n5- Is there any available information on Keivan Jamali's personal life or background?\\n\\n6- Is Keivan Jamali associated with any specific industry or field?\\n\\n7- Are there any notable works or projects attributed to Keivan Jamali?\\n\\n8- Is Keivan Jamali active on social media or other online platforms?\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sub_queries(\"who is Keivan jamali?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an AI language model assistant. Your task is to generate five \\ndifferent versions of the given user question to retrieve relavant documents from a vector \\ndatabase. By generating mulitple perspectives on the user quesion, your goal is to help \\nthe user overcome some of the limitations of the distance-based similarity search.\\nProvide these alternative questions seprated by newlines. Original questions: {question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relavant documents from a vector \n",
    "database. By generating mulitple perspectives on the user quesion, your goal is to help \n",
    "the user overcome some of the limitations of the distance-based similarity search.\n",
    "Provide these alternative questions seprated by newlines. Original questions: {question}\"\"\"\n",
    "\n",
    "multiquery_prompt = ChatPromptTemplate.from_template(template)\n",
    "multiquery_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multi_queries(query):\n",
    "    chain  = (multiquery_prompt\n",
    "        | model_groq\n",
    "        | StrOutputParser()\n",
    "        | (lambda x: x.split(\"\\n\"))\n",
    "    )\n",
    "    multi_queries = chain.invoke({\"question\": query})\n",
    "    display(Markdown(\"==========================================\\n\\n\" + \"Sub-Queries  :  \\n\\n\" + \"\\n\\n\".join(multi_queries) + \"\\n\\n==========================================\"))\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "==========================================\n",
       "\n",
       "Sub-Questions  :  \n",
       "\n",
       "1- What is the full name of Keivan?\n",
       "\n",
       "2- What is Keivan's nationality?\n",
       "\n",
       "3- What is Keivan known for (e.g. profession, achievement, etc.)?\n",
       "\n",
       "4- Is Keivan a public figure, and if so, in what context?\n",
       "\n",
       "5- Are there any notable achievements or contributions associated with Keivan?\n",
       "\n",
       "=========================================="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "==========================================\n",
       "\n",
       "Sub-Queries  :  \n",
       "\n",
       "Here are five different versions of each user question to retrieve relevant documents from a vector database:\n",
       "\n",
       "\n",
       "\n",
       "1. What is the full name of Keivan?\n",
       "\n",
       " \n",
       "\n",
       "Keivan's full name is what?\n",
       "\n",
       "What is Keivan's complete name?\n",
       "\n",
       "Can you provide the full name of the individual known as Keivan?\n",
       "\n",
       "What is the official name of Keivan?\n",
       "\n",
       "\n",
       "\n",
       "2. What is Keivan's nationality?\n",
       "\n",
       "\n",
       "\n",
       "What country is Keivan from?\n",
       "\n",
       "What is Keivan's country of origin?\n",
       "\n",
       "What nationality does Keivan hold?\n",
       "\n",
       "Is Keivan a citizen of a specific country?\n",
       "\n",
       "What is Keivan's ethnic background?\n",
       "\n",
       "\n",
       "\n",
       "3. What is Keivan known for (e.g. profession, achievement, etc.)?\n",
       "\n",
       "\n",
       "\n",
       "What is Keivan's profession or area of expertise?\n",
       "\n",
       "What is Keivan famous for?\n",
       "\n",
       "What notable achievements has Keivan accomplished?\n",
       "\n",
       "What is Keivan recognized for in his field?\n",
       "\n",
       "What is Keivan's claim to fame?\n",
       "\n",
       "\n",
       "\n",
       "4. Is Keivan a public figure, and if so, in what context?\n",
       "\n",
       "\n",
       "\n",
       "Is Keivan a well-known individual?\n",
       "\n",
       "What is Keivan's public profile?\n",
       "\n",
       "Is Keivan a celebrity or notable figure?\n",
       "\n",
       "In what capacity is Keivan a public figure?\n",
       "\n",
       "Is Keivan widely recognized in a particular field?\n",
       "\n",
       "\n",
       "\n",
       "5. Are there any notable achievements or contributions associated with Keivan?\n",
       "\n",
       "\n",
       "\n",
       "What significant contributions has Keivan made?\n",
       "\n",
       "What notable accomplishments is Keivan known for?\n",
       "\n",
       "Has Keivan achieved any notable milestones?\n",
       "\n",
       "What impact has Keivan had in his field?\n",
       "\n",
       "What are Keivan's most notable achievements?\n",
       "\n",
       "=========================================="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an AI language model assistant. Your task is to generate five \\ndifferent versions of the given user question to retrieve relavant documents from a vector \\ndatabase. By generating mulitple perspectives on the user quesion, your goal is to help \\nthe user overcome some of the limitations of the distance-based similarity search.\\nProvide these alternative questions seprated by newlines. Original questions: {question}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000023A45558F20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000023A45559E20>, model_name='llama-3.1-70b-versatile', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_multi_queries(generate_sub_queries(\"Who is Keivan?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "doc_path = r\"D:\\All Python\\Pure-Python\\P4\\06-PromptEngineering\\Project 3 - OpenAI\\KeivanJamali_doc\"\n",
    "document = []\n",
    "\n",
    "for file_name in os.listdir(doc_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        # print(len(document))\n",
    "        file_path = os.path.join(doc_path, file_name)\n",
    "        loader = TextLoader(file_path, encoding='utf-8')\n",
    "        docs = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=300,\n",
    "            chunk_overlap=10,\n",
    "            separators=\"\\n\\n\"\n",
    "        )\n",
    "        result = text_splitter.split_documents(docs)\n",
    "        document += result\n",
    "\n",
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Use pytorch device_name: cpu\n",
      "INFO: Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents is  :  242\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "db_k1 = Chroma.from_documents(document, embeddings)\n",
    "retriever = db_k1.as_retriever()\n",
    "print(f\"Number of documents is  :  {db_k1._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    \n",
    "    unique_docs = list(set(flattened_docs))\n",
    "\n",
    "    return [loads(doc) for doc in unique_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the following question based on this context:\\n{context}\\nQuestion: {question}\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_template = \"\"\"Answer the following question based on this context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
    "rag_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def query(query, retriever):\n",
    "    retrieval_chain = (generate_multi_queries(generate_sub_queries(query)) \n",
    "                       | retriever.map()\n",
    "                       | get_unique_union)\n",
    "    docs = retrieval_chain.invoke({\"question\": query})\n",
    "    display(f\"Number of document that is used is ({len(docs)})\")\n",
    "    # return docs\n",
    "    final_rag_chain = ({\"context\": retrieval_chain, \"question\": RunnablePassthrough()} \n",
    "                       | rag_prompt\n",
    "                       | model_groq\n",
    "                       | StrOutputParser())\n",
    "    return final_rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "==========================================\n",
       "\n",
       "Sub-Questions  :  \n",
       "\n",
       "1- Who is Keivan Jamali and what is his profession?\n",
       "\n",
       "2- What type of projects is Keivan Jamali known for working on?\n",
       "\n",
       "3- Can you provide a list of Keivan Jamali's notable projects?\n",
       "\n",
       "4- Are Keivan Jamali's projects focused on a specific industry or field?\n",
       "\n",
       "5- What is the most recent project that Keivan Jamali has worked on?\n",
       "\n",
       "6- Are there any upcoming projects that Keivan Jamali is involved in?\n",
       "\n",
       "7- How can I find more information about Keivan Jamali's projects?\n",
       "\n",
       "8- Are Keivan Jamali's projects available to the public or are they private?\n",
       "\n",
       "=========================================="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "==========================================\n",
       "\n",
       "Sub-Queries  :  \n",
       "\n",
       "Here are five alternative versions of each user question to help retrieve relevant documents from a vector database:\n",
       "\n",
       "\n",
       "\n",
       "1. Who is Keivan Jamali and what is his profession?\n",
       "\n",
       "\n",
       "\n",
       "Keivan Jamali's background and occupation\n",
       "\n",
       "What does Keivan Jamali do for a living?\n",
       "\n",
       "Keivan Jamali's professional profile\n",
       "\n",
       "Information about Keivan Jamali's career\n",
       "\n",
       "Keivan Jamali's job title and expertise\n",
       "\n",
       "\n",
       "\n",
       "2. What type of projects is Keivan Jamali known for working on?\n",
       "\n",
       "\n",
       "\n",
       "Keivan Jamali's project specialties\n",
       "\n",
       "The types of projects Keivan Jamali is involved in\n",
       "\n",
       "Keivan Jamali's areas of project expertise\n",
       "\n",
       "Project genres associated with Keivan Jamali\n",
       "\n",
       "Keivan Jamali's typical project scope\n",
       "\n",
       "\n",
       "\n",
       "3. Can you provide a list of Keivan Jamali's notable projects?\n",
       "\n",
       "\n",
       "\n",
       "Notable projects by Keivan Jamali\n",
       "\n",
       "Keivan Jamali's most notable works\n",
       "\n",
       "A list of Keivan Jamali's significant projects\n",
       "\n",
       "Keivan Jamali's top projects\n",
       "\n",
       "Keivan Jamali's most famous projects\n",
       "\n",
       "\n",
       "\n",
       "4. Are Keivan Jamali's projects focused on a specific industry or field?\n",
       "\n",
       "\n",
       "\n",
       "Keivan Jamali's industry specialization\n",
       "\n",
       "The fields in which Keivan Jamali works\n",
       "\n",
       "Keivan Jamali's project focus areas\n",
       "\n",
       "Is Keivan Jamali's work limited to a specific sector?\n",
       "\n",
       "Keivan Jamali's areas of industry expertise\n",
       "\n",
       "\n",
       "\n",
       "5. What is the most recent project that Keivan Jamali has worked on?\n",
       "\n",
       "\n",
       "\n",
       "Keivan Jamali's latest project\n",
       "\n",
       "Recent projects by Keivan Jamali\n",
       "\n",
       "Keivan Jamali's current project\n",
       "\n",
       "What is Keivan Jamali working on now?\n",
       "\n",
       "Keivan Jamali's newest project\n",
       "\n",
       "\n",
       "\n",
       "6. Are there any upcoming projects that Keivan Jamali is involved in?\n",
       "\n",
       "\n",
       "\n",
       "Keivan Jamali's future projects\n",
       "\n",
       "Upcoming projects featuring Keivan Jamali\n",
       "\n",
       "What's next for Keivan Jamali?\n",
       "\n",
       "Keivan Jamali's projects in development\n",
       "\n",
       "Keivan Jamali's forthcoming projects\n",
       "\n",
       "\n",
       "\n",
       "7. How can I find more information about Keivan Jamali's projects?\n",
       "\n",
       "\n",
       "\n",
       "Resources for learning about Keivan Jamali's projects\n",
       "\n",
       "Where to find information on Keivan Jamali's projects\n",
       "\n",
       "Keivan Jamali's project documentation\n",
       "\n",
       "How to stay updated on Keivan Jamali's projects\n",
       "\n",
       "Keivan Jamali's project portfolio\n",
       "\n",
       "\n",
       "\n",
       "8. Are Keivan Jamali's projects available to the public or are they private?\n",
       "\n",
       "\n",
       "\n",
       "Keivan Jamali's project accessibility\n",
       "\n",
       "Are Keivan Jamali's projects publicly available?\n",
       "\n",
       "Keivan Jamali's project visibility\n",
       "\n",
       "Can the public access Keivan Jamali's projects?\n",
       "\n",
       "Keivan Jamali's project confidentiality\n",
       "\n",
       "=========================================="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Number of document that is used is (6)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Keivan Jamali has a project portfolio that can be found at https://keivanjamali.com/keivan-jamali-project-portfolio/azadi-tower-structural-analysis/. Additionally, one of his projects is mentioned as \"Azadi Tower Structural Analysis\"."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "answer = query(\"Tell me about Keivan Jamali's projects.\", retriever)\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import RetrievalQA\n",
    "# chain2 = RetrievalQA.from_chain_type(\n",
    "#     llm=model_groq,\n",
    "#     chain_type=\"stuff\",\n",
    "#     retriever=retriever,\n",
    "#     return_source_documents=True\n",
    "# )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
